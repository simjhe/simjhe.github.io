{
  "hash": "2eb2704f8e147be541e529a5de6d403e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"How to set up a web scraping environment with R and Selenium on Ubuntu\"\ndate: 2024-05-23\ndescription: \"Learn in this tutorial how to create a simple and beginner-friendly web scraping environment with Selenium and R on Ubuntu\"\nimage: \"img/teaser_img_scraping-tutorial.png\"\ncategories:\n  - R\n  - Web scraping\n  - Linux\nresources:\n  - \"img/*\"\nformat:\n  html: \n    shift-heading-level-by: 1\ntoc-location: left\nexecute: \n  eval: false\n---\n\n\n\n\n## Preface: Required software\n\nWhenever we want to do something great with a computer, we should have an operating system installed on it. In this tutorial, I use Ubuntu. I assume that some steps of my tutorial can also be transferred to other (especially Unix-based) operating systems. However, since I have not tried my tutorial on another operating system, I can only “guarantee”^[If any problems occur despite my “guarantee”, plz don't sue me - just [write me an e-mail](mailto:simhe051@student.liu.se) ^^] that my instructions will work for Ubuntu (I am using 22.04).\n\nApart from an operating system, you also need an installation of R and the Docker Engine for Ubuntu. For writing code in R, I also recommend using a suitable IDE such as RStudio. If you already have these installed on your system, you can get started right away and [pull a Docker image from Selenium](index.html#pull-docker-image-of-selenium).\n\nIf you don't have R installed yet, you can install it from one of the [CRAN mirrors in your country](https://cran.r-project.org/mirrors.html). You can install RStudio [here](https://posit.co/download/rstudio-desktop/). To install the Docker Engine on your machine, follow the instructions on the [docker website](https://docs.docker.com/engine/install/ubuntu/#install-using-the-repository). Simply copy the code given on the page into a terminal window and you should be good to go.\n\nAfter you have installed all the necessary software, we can move on to the main tool we will use to automate our browser: Selenium.\n\n## Pull docker image of Selenium\n\nSelenium is a software with which we can automate a browser. Many of the functions that Selenium contains are therefore very helpful for scraping content from a website. In this tutorial, we will not install Selenium directly on our system but run an image of Selenium within a Docker container.\n\nTo use Selenium within a container, we first have to pull an image of it in the Docker Engine. Depending on which browser you want to use, you can pull different versions for different browsers. Standalones are available for [Firefox](https://hub.docker.com/r/selenium/standalone-firefox), [Chrome](https://hub.docker.com/r/selenium/standalone-chrome), and [Edge](https://hub.docker.com/r/selenium/standalone-edge).\n\nSince I prefer to use Firefox, I’ll install a version that “uses” Firefox. With the following command in the terminal, you can pull the image:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker pull selenium/standalone-firefox \n```\n:::\n\n\n::: {.callout-important}\n## Issues with pulling the image?\n\nWhen I first tried to pull the image of Selenium, I got the error message: denied while trying to connect to the Docker daemon socket at unix\n\nThis error usually occurs when the user who runs the command to pull the image doesn't have the necessary permissions to access the Docker daemon.\n\nFollow these steps to fix this problem permanently:\n\n1.  Add your user to the Docker group, which grants the user permission to interact with the Docker daemon. You can do this with the following command:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsudo usermod -aG docker $USER \n```\n:::\n\n\n2.  After adding your user to the Docker group, you can run the following command to apply the changes to the current session: \n\n\n::: {.cell}\n\n```{.bash .cell-code}\nnewgrp docker\n```\n:::\n\n\n3.  After logging back in, you can verify that your user has access to Docker by running a Docker command without sudo, such as: \n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker ps\n```\n:::\n\n\n4.  Try again to pull the docker image\n:::\n\n## Set up a Docker container with Selenium\n\nAfter we have successfully pulled the Selenium image, we can now create a Docker container in which we run Selenium. To do so, use the following command in the terminal:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker run -d -p 4444:4444 -p 7900:7900 --shm-size=\"2g\" selenium/standalone-firefox:latest \n```\n:::\n\n\nThis command creates and starts a new Docker container based on the latest selenium/standalone-firefox image. \n\n\n```{=html}\n<a data-bs-toggle=\"collapse\" data-bs-target=\"#collapseElement\" aria-expanded=\"false\" aria-controls=\"collapseElement\">\n <b>Are you interested in what all the elements of this command mean? Click here to deconstruct it.</b>\n</a> <br>\n<div class=\"collapse\" id=\"collapseElement\">\n  <div class=\"card card-body\">\n<ul>\n    <li><strong>docker run</strong>: This is the command used to create and start a new Docker container based on a specified Docker image</li>\n    <li><strong>-d</strong>: This activates the \"detached mode.\" It tells Docker to run the container in the background and print the container ID</li>\n    <li><strong>-p 4444:4444</strong>: This option maps port 4444 on the host machine to port 4444 inside the Docker container. This allows communication with the Selenium server from outside the container</li>\n    <li><strong>-p 7900:7900</strong>: Similar to the previous option, this maps port 7900 on the host machine to port 7900 inside the Docker container. This port is used for Virtual Network Computing (VNC), which later allows us to see what our web scraper sees when navigating the Internet</li>\n    <li><strong>--shm-size=\"2g\"</strong>: This option sets the size of the shared memory segment for the container. In this case, it's set to 2 gigabytes (2g)</li>\n    <li><strong>selenium/standalone-firefox:latest</strong>: This is the Docker image name and tag. It specifies the image to use for creating the container. Here, we are using the selenium/standalone-firefox image. The :latest tag indicates that it's using the latest version of the image.</li>\n</ul>\n  </div>\n</div>\n<br>\n```\n\n\nWe have now managed to complete all preparations so that the web scraping can begin. But, before we can control our web scraper in R, we always need to make sure that the Docker container with the Selenium image is running.\n\n## Start (and stop) the Selenium Docker container\n\nTo know whether our Docker container with Selenium is running, we should get an overview of all active Docker containers. To get an overview of all running containers, use this command in the terminal:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker ps\n```\n:::\n\n\nIf you also want to see containers that are not active at the moment but ran in the past, use the command:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker ps -a\n```\n:::\n\n\nThe second command comes in really handy if you want to start a container that you have already used in the past. Then you can simply copy the ID of the desired container from the overview of already used containers and then restart the old container with the following command:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker start <paste here the ID of the desired container>\n```\n:::\n\n\n::: {.callout-tip}\n## Stopping a container\n\nI advise you to stop the container after you finish the scraping. A running container requires computing power from your system and may cause other processes on the system to slow down. \n\nTo stop the container, use the command:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndocker stop <ID of running container>\n```\n:::\n\n:::\n\n## Control the scraper in R \n\nOnce our Docker container with Selenium is running, we can start programming our web scraper in R. To do so, we use the R package *selenium*, which you can install as usual with ```install.packages(“selenium”)``` in R. This package contains numerous functions with which we can control the behavior of the automated browser. Explaining every function would probably require a separate blog entry - so I will only give a rough overview of the most important functions here: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nSeleniumSession$new(browser = \"firefox\") -> object # starts the automated browser (here we need to assign the output of the function to an R object which we will use to address the browser in further instructions) \n\nobject$navigate(\"insert here an URL\") # navigates the browser to an URL\n\nobject$find_element # helps us to address a specific element on a webpage (for example with an XPATH)\n\nobject$get_page_source() # retrieves the source code of the webpage\n```\n:::\n\n\n::: {.callout-tip}\n## Listen on ports to see what our scraper is doing\n\nIn most scraping projects, the automated browser has to click through various elements or make inputs at specific points on the website. Therefore, it is helpful to see how the automated browser navigates through a site so that we can see potential barriers and take them into account when programming the scraper. The great thing about Selenium is that it comes with a built-in VNC that allows us to do just that. All we need to do is type the following URL into a browser:\n\n<http://localhost:7900/?autoconnect=1&resize=scale&password=secret> \n\nIn addition, we can obtain an overview of the active automated browsers when listening on port 4444. This can be interesting if you want to run several scrapers simultaneously. To listen on port 4444, type in your browser:\n\n<http://localhost:4444>\n:::\n\nIf you have any questions or feedback about this blog post, please feel free to [send me an e-mail](mailto:simhe051@student.liu.se). Otherwise, I wish you some happy scraping!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}